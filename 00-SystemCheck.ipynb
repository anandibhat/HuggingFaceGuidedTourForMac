{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47040240-fa7e-431b-924f-02ef1696779b",
   "metadata": {},
   "source": [
    "# Installed software check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29867cbd-8ba7-47ce-afd3-c38f5bc1091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.5.1+cu124\n",
      "Your version of Pytorch does not support MPS, Pytorch will be slow.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    print(f\"Pytorch version: {torch.__version__}\")\n",
    "    is_torch = True\n",
    "    if torch.backends.mps.is_available() is True:\n",
    "        print(\"Apple Metal MPS acceleration ok.\")\n",
    "    else:\n",
    "        print(\"Your version of Pytorch does not support MPS, Pytorch will be slow.\")\n",
    "except:\n",
    "    print(\"Pytorch is not installed. Please install pytorch!\")\n",
    "    is_torch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f22a840-d023-438d-b5c2-0539d7fe19ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLX is not installed, it's optional, so this is not a fatal error.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import mlx.core as mx\n",
    "    print(f\"MLX version: {mx.__version__}\")\n",
    "    is_mlx = True\n",
    "    print(\"Apple MLX framework is installed ok\")\n",
    "except:\n",
    "    print(\"MLX is not installed, it's optional, so this is not a fatal error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db547c2-4f6f-4016-8719-887a89f3be66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 17:49:10.553092: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-30 17:49:10.561119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730306950.570832    6322 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730306950.573723    6322 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-30 17:49:10.583742: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.18.0\n",
      "GPU support ok: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"Tensorflow version: {tf.__version__}\")\n",
    "    is_tensorflow = True\n",
    "    devs=tf.config.list_physical_devices('GPU')\n",
    "    if devs is None or len(devs)==0:\n",
    "        print(\"You have not installed the metal drivers, tensorflow will be slow\")\n",
    "    else:\n",
    "        print(f\"GPU support ok: {devs}\")\n",
    "except:\n",
    "    print(\"Tensoflow not installed, but it's optional, so this is not a fatal error.\")\n",
    "    is_tensorflow = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fc1919-f641-4cd0-968a-b7c1738059cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX is installed and is using: NVIDIA GeForce RTX 4070 Ti, ok\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import jax\n",
    "    is_jax = True\n",
    "    device_type = jax.devices()[0].device_kind\n",
    "    print(f\"JAX is installed and is using: {device_type}, ok\")\n",
    "except:\n",
    "    print(\"JAX is not installed, it's optional, so this is not a fatal error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf367403-bbcd-4841-a59b-66ead3dd1697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.46.1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import transformers\n",
    "    from transformers import pipeline\n",
    "    print(f\"Transformers version: {transformers.__version__}\")\n",
    "    is_huggingface = True\n",
    "except Exception as e:\n",
    "    print(f\"HuggingFace transformers is not installed. This won't work! {e}\")\n",
    "    is_huggingface = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197a353a-01bb-4ec4-b6be-9bfffda2c568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All looks good, let's try a simple sentiment analysis:\n"
     ]
    }
   ],
   "source": [
    "if is_huggingface is False or is_torch is False:\n",
    "    print(\"The minimal software is not installed. Please check that PyTorch and HuggingFace are installed, following the HowTo!\")\n",
    "    print(\"At this stage, non of the examples will work!\")\n",
    "    print(\"\")\n",
    "    print(\"Hint: all software installed with `pip` needs to be installed into the same active environment,\")\n",
    "    print(\"otherwise components won't see each other.\")\n",
    "else:\n",
    "    print(\"All looks good, let's try a simple sentiment analysis:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3114971-5678-4c9f-8b2e-a618eecc2513",
   "metadata": {},
   "source": [
    "## Sentiment analysis minimal example\n",
    "\n",
    "> **Note:** when this pipeline is run for the first time, several hundred megabytes of models are downloaded once.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07521c38-02bb-4b12-b336-d068ca4d5442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a762537d65764814ac38835474173722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf43c1f358b436f9a8a753896daf970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c49bde23eb248b691444229573e45cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pipeline(\"sentiment-analysis\", framework='pt')\n",
    "nlp(\"We are very happy to show you the ðŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19962824-6493-4bdd-8446-dc1916720fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.46.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc728f-dc27-49de-bbef-e4b0102cfedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
